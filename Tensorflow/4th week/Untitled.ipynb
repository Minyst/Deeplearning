{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab00828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, Model\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "187074bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48bcbd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(image,label):\n",
    "    image = tf.image.convert_image_dtype(image,tf.float32)\n",
    "    image = tf.image.resize(image,size=(IMG_SIZE,IMG_SIZE))\n",
    "    label = tf.cast(label,tf.int32)\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd44b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augmentation(image,label,seed):\n",
    "    new_seed = tf.random.experimental.stateless_split(seed,num=1)[0,:]\n",
    "    image = tf.image.resize_with_crop_or_pad(image,int(IMG_SIZE*1.1),int(IMAGE_SIZE*1.1))\n",
    "    image = tf.image.stateless_random_crop(image,size=[IMG_SIZE,IMG_SIZE,3],seed=new_seed))\n",
    "    image = tf.image.stateless_random_brightness(image,max_delta=0.5,seed=new_seed)\n",
    "    #image = tf.clip_by_value(image,clip_value_min=0,clip_value_max=1)\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac5ed9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = tf.random.Generator.from_seed(123,alg='philox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d15a92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_augmentation(image,label):\n",
    "    seed = rng.make_seeds(2)[0]\n",
    "    image,label = image_augmentation(image,label,seed)\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b862504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_train = tf.data.Dataset.from_tensor_slices((train_images,train_labels))\n",
    "datasets_train = datasets_train.shuffle(buffer_size=len(train_labels))\n",
    "datasets_train = datasets_train.map(image_preprocess,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "datasets_train = datasets_train.map(wrapper_augmentation,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "datasets_train = datasets_train.batch(batch_size=32)\n",
    "datasets_train = datasets_train.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c0ae283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_test = tf.data.Dataset.from_tensor_slices((test_images,test_labels))\n",
    "datasets_test = datasets_test.map(image_preprocess,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "datasets_test = datasets_test.batch(batch_size=32)\n",
    "datasets_test = datasets_test.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff4e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shpae = (IMG_SIZE,IMG_SIZE,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68a49aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNetV2 = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n",
    "                                                include_top=False,\n",
    "                                                weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "940a8421",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = MobileNetV2.input\n",
    "x = MobileNetV2.output\n",
    "x = layers.GlobalMaxPooling2D()(x)\n",
    "x = layers.LayerNormalization()(x)\n",
    "#outputs = layers.Dense(len(class_names),activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dafc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b40812",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-03),\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a55a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(datasets_train,epochs=50,validation_data=datasets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad6fd07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model.predict(datasets_test)\n",
    "# pred = np.argmax(pred[0])\n",
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "347caadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d321046d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d5f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03016d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa051ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca8f620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8885e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f41b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b0ef6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea128a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype(np.float32)\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images.astype(np.float32)\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa425a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype(np.int32)\n",
    "test_labels = test_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ba88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90747837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, size=(IMG_SIZE, IMG_SIZE))\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed2e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augmentation(image, label, seed):\n",
    "    # image = tf.image.resize_with_crop_or_pad(image, target_height=224, target_width=224)\n",
    "    # image = tf.image.random_crop(image, size=(224, 224, 3))\n",
    "    new_seed = tf.random.experimental.stateless_split(seed, num=1)[0, :]\n",
    "    \n",
    "    # Random crop back to the original size.\n",
    "    image = tf.image.resize_with_crop_or_pad(image, int(IMG_SIZE*1.1), int(IMG_SIZE*1.1))\n",
    "    image = tf.image.stateless_random_crop(image, size=[IMG_SIZE, IMG_SIZE, 3], seed=seed)\n",
    "    \n",
    "    # Random brightness.\n",
    "    image = tf.image.stateless_random_brightness(image, max_delta=0.5, seed=new_seed)\n",
    "    \n",
    "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator.\n",
    "rng = tf.random.Generator.from_seed(123, alg='philox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b59d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a wrapper function for updating seeds.\n",
    "def wrapper_augmentation(image, label):\n",
    "    seed = rng.make_seeds(2)[0]\n",
    "    image, label = image_augmentation(image, label, seed)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430660fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_train = tf.data.Dataset.from_tensor_slices((train_images, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_train = datasets_train.shuffle(buffer_size=len(train_labels))\n",
    "datasets_train = datasets_train.map(image_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "datasets_train = datasets_train.map(wrapper_augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "datasets_train = datasets_train.batch(batch_size=32)\n",
    "datasets_train = datasets_train.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_test = tf.data.Dataset.from_tensor_slices((test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b99092",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_test = datasets_test.map(image_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "datasets_test = datasets_test.batch(batch_size=32)\n",
    "datasets_test = datasets_test.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253495b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440e28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNetV2 = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=input_shape,\n",
    "    include_top=False,\n",
    "    weights=None\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ab3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = MobileNetV2.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74228ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MobileNetV2.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae7f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.LayerNormalization()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = layers.Dense(len(class_names), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a244b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06556aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-03),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38282ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "history  = model.fit(datasets_train, epochs=50, validation_data=datasets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(datasets_test)\n",
    "np.argmax(predictions,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e830af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e18a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8addcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d73a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e9ef3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b2bae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78917d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1ac02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6d78d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
