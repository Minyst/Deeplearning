{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d85ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils import gen_batches,shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5bf76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "def macro_f1_score(y_true,y_pred):\n",
    "    y_pred = np.argmax(y_pred,1)\n",
    "    f1_scores=[]\n",
    "    for k in range(num_classes):\n",
    "        y_true_k = (y_true == k)\n",
    "        y_pred_k = (y_pred == k)\n",
    "        f1_k = f1_score(y_true_k,y_pred_k)\n",
    "        f1_scores.append(f1_k)\n",
    "    return np.mean(f1_scores)    \n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "def macro_f1_score(y_true,y_pred):\n",
    "    y_pred = np.argmax(y_pred,1)\n",
    "    f1_scores = []\n",
    "    for k in range(num_classes):\n",
    "        y_true_k = (y_true == k)\n",
    "        y_pred_k = (y_pred == k)\n",
    "        f1_k = f1_score(y_true_k,y_pred_k,zero_division=0)\n",
    "        f1_scores.append(f1_k)\n",
    "    return np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f7808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true,y_pred):\n",
    "    f1 = tf.py_function(func=macro_f1_score,inp=[y_true,y_pred],Tout=tf.float32)\n",
    "    return f1\n",
    "\n",
    "def custom_metric(y_true,y_pred):\n",
    "    f1 = tf.py_function(func=macro_f1_score,inp=[y_true,y_pred],Tout=tf.float32)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metric=[tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "       custom_metric]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "              custom_metric\n",
    "              ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f629872",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "         batch_size=128,\n",
    "         epoch=10,\n",
    "         validation_data=(x_valid,y_valid))\n",
    "\n",
    "model.fit(x = x_train,\n",
    "          y= y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = model.predict(x_valid)\n",
    "y_pred = np.argmax(val_pred,1)\n",
    "y_true = np.array(y_valid)\n",
    "\n",
    "val_pred = model.predict(x_valid)\n",
    "y_pred = np.argmax(val_pred,1)\n",
    "y_true = np.array(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce885b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.dense = Dense(1024,activation='relu')\n",
    "        self.dropout = Dropout(0.2)\n",
    "        self.logits = Dense(1,activation='sigmoid')\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        x = self.dense(inputs)\n",
    "        x = self.dropout(x)\n",
    "        out = self.logits(x)\n",
    "        return out\n",
    "\n",
    "subclassing_model = MyModel()\n",
    "\n",
    "class MyModel(Model): \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.dense = Dense(1024, activation='relu')\n",
    "        self.dropout = Dropout(0.2)\n",
    "        self.logits = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense(inputs)\n",
    "        x = self.dropout(x)\n",
    "        out = self.logits(x)\n",
    "        return out\n",
    "\n",
    "subclassing_model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ea46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclassing_model.build(input_shape=(None,10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_fn = tf.keras.losses.BianaryCrossentropy(from_logits=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "subclassing_model.build(input_shape=(None, 110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93281de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_total=10\n",
    "batch_size=128\n",
    "\n",
    "total_epoch = 10\n",
    "batch_size = 128\n",
    "\n",
    "train_batches = list(gen_batches(len(x_train),batch_size))\n",
    "train_batches = list(gen_batches(len(train_x), batch_size))\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "valid_loss = tf.keras.metrics.Mean()\n",
    "\n",
    "train_acc = tf.keras.metrics.BinaryAccuracy()\n",
    "valid_acc = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "train_auc = tf.keras.metrics.AUC()\n",
    "valid_auc = tf.keras.metrics.AUC()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "valid_loss = tf.keras.metrics.Mean()\n",
    "\n",
    "train_acc = tf.keras.metrics.BinaryAccuracy()\n",
    "valid_acc = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "train_auc = tf.keras.metrics.AUC()\n",
    "valid_auc = tf.keras.metrics.AUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eae5638",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "for epoch in range(total_epoch):\n",
    "    \n",
    "    train_loss.reset_state()\n",
    "    valid_loss.reset_state()\n",
    "    \n",
    "    ####################################################################################################\n",
    "    # training\n",
    "    (shuffle_x, shuffle_y) = shuffle(train_x, train_y)\n",
    "    \n",
    "    for batch in train_batches:\n",
    "        \n",
    "        batch_x = shuffle_x[batch]\n",
    "        batch_y = shuffle_y[batch]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = subclassing_model(batch_x)\n",
    "            loss = loss_fn(batch_y, logits)\n",
    "\n",
    "        gradients = tape.gradient(loss, subclassing_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, subclassing_model.trainable_variables))\n",
    "        \n",
    "        train_loss.update_state(loss)\n",
    "        train_acc.update_state(batch_y, logits)\n",
    "        train_auc.update_state(batch_y, logits)\n",
    "        \n",
    "    ####################################################################################################\n",
    "    # history\n",
    "    logits = subclassing_model.predict(valid_x, verbose=False)\n",
    "    loss = loss_fn(valid_y, logits)\n",
    "    valid_loss.update_state(loss)\n",
    "    valid_acc.update_state(valid_y, logits)\n",
    "    valid_auc.update_state(valid_y, logits)\n",
    "    \n",
    "    msg = \"epoch: {:>5d} - loss: {:>.5f} - accuracy: {:>.3%} - auc: {:>.3%} - val_loss: {:>.5f} - val_accuracy: {:>.3%} - val_auc: {:>.3%}\"\n",
    "    print(msg.format(epoch, \n",
    "                     train_loss.result().numpy(), train_acc.result().numpy(), train_auc.result().numpy(), \n",
    "                     valid_loss.result().numpy(), valid_acc.result().numpy(), valid_auc.result().numpy()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faff1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "def macro_f1_score(y_true,y_pred):\n",
    "    y_pred = np.argmax(y_pred,1)\n",
    "    f1_scores = []\n",
    "    for k in range(num_classes):\n",
    "        y_true_k = (y_true == k)\n",
    "        y_pred_k = (y_pred == k)\n",
    "        f1_k = f1_score(y_true_k,y_pred_k)\n",
    "        f1_scores.append(f1_k)\n",
    "    return np.mean(f1_scores)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106f83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true,y_pred):\n",
    "    f1 = tf.py_function(func=macro_f1_score,inp=[y_true,y_pred],Tout=tf.float32)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c989707",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.dense = Dense(1024,activation='relu')\n",
    "        self.dropout = Dropout(0.2)\n",
    "        self.logits = Dense(1,activation='sigmoid')\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        x = self.dense(inputs)\n",
    "        x = self.dropout(x)\n",
    "        out = self.logits(x)\n",
    "        return out\n",
    "\n",
    "subclassing_model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293ea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace91e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclassing_model.build(input_shape=(None,110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38223dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclassing_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44537af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fb97ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37634f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc421678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1afadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653f922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97a1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd9ccbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede26d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10990d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f14c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d085a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import gen_batches,shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9143c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model): \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        hidden_layer=[]\n",
    "        for _ in range(5):\n",
    "            self.dense = Dense(1024, activation='relu')\n",
    "            self.dropout = Dropout(0.2)\n",
    "        self.logits = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs,training=False):\n",
    "        x = self.dense(inputs)\n",
    "        for layer in hidden_layer:\n",
    "            x = layer(x)\n",
    "            x = self.dropout(x,training=training)\n",
    "        out = self.logits(x)\n",
    "        return out\n",
    "    \n",
    "subclassing_model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daf05f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean()\n",
    "valid_loss = tf.keras.metrics.Mean()\n",
    "\n",
    "train_acc = tf.keras.metrics.BinaryAccuracy()\n",
    "valid_acc = tf.keras.metrics.BinarcyAccuracy()\n",
    "\n",
    "train_auc = tf.keras.metrics.AUC()\n",
    "valid_auc = tf.keras.metrics.AUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc16cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = 10\n",
    "batch_size = 128\n",
    "train_batches = list(gen_batches(len(x_train),batch_size))\n",
    "valid_batches = list(gen_batches(len(x_valid),batch_size))\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    \n",
    "    train_loss.reset_state()\n",
    "    valid_loss.reset_state()\n",
    "    \n",
    "    (x_shuffle,y_shuffle) = shuffle(x_train,y_train)\n",
    "    (val_x_shuffle,val_y_shuffle) = shuffle(x_valid,y_valid)\n",
    "    \n",
    "    for batch in train_batches:\n",
    "        \n",
    "        x_batch = x_shuffle[batch]\n",
    "        y_batch = y_shuffle[batch]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            logits = subclassing_model(x_batch,training=True)\n",
    "            loss = loss_fn(y_batch,logits)\n",
    "            \n",
    "        gradients = tape.gradient(loss,subclassing_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients,subclassing_model.trainable_variables))\n",
    "        \n",
    "        train_loss.update_state(loss)\n",
    "        train_acc.update_state(y_batch,logits)\n",
    "        train_auc.update_state(y_batch,logits)\n",
    "     \n",
    "    for batch in valid_batches:\n",
    "        val_x_batch = val_x_shuffle[batch]\n",
    "        val_y_batch = val_y_shuffle[batch]\n",
    "        \n",
    "        logits = subclassing_model.predict(val_x_batch,training=False)\n",
    "        loss = loss_fn(val_y_batch,logits)\n",
    "    \n",
    "        valid_loss.update_state(loss)\n",
    "        valid_acc.update_state(val_y_batch,logits)\n",
    "        valid_auc.update_state(val_y_batch,logits)\n",
    "    \n",
    "    print(msg)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146daf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = subclassing_model.predict(x_test,training=False)\n",
    "pred = np.argmax(pred,1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db41007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03acf3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import gen_batches,shuffle\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "def macro_f1_score(y_true,y_pred):\n",
    "    y_pred = np.argmax(y_pred,1)\n",
    "    f1_scores = []\n",
    "    for k in range(num_classes):\n",
    "        y_true_k = (y_true == k)\n",
    "        y_pred_k = (y_pred == k)\n",
    "        f1_scores.append(f1_score(y_true_k,y_pred_k))\n",
    "    return np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab31ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true,y_pred):\n",
    "    f1 = tf.py_function(func=macro_f1_score,inp=[y_true,y_pred],Tout=tf.float32)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05214c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(),custom_metric]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train,\n",
    "         y=y_train,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_valid,y_valid)         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423dd5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = model.predict(x_valid)\n",
    "y_true = np.array(y_valid)\n",
    "y_pred = np.argmax(val_pred,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b865fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_f1_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6480fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.dense = Dense(1024,activation='relu')\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.logits = Dense(1,activation='sigmoid')\n",
    "        \n",
    "    def call(self,inputs,training=False):\n",
    "        x = self.dense(inputs)\n",
    "        x = self.dropout(x,training=training)\n",
    "        out = self.logits(x)\n",
    "        return out\n",
    "    \n",
    "subclassing_model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c203a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b704c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = list(gen_batches(len(x_train),batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de685c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean()\n",
    "test_loss = tf.keras.metrics.Mean()\n",
    "\n",
    "train_acc = tf.keras.metrics.BinaryAccuracy()\n",
    "test_acc = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "train_auc = tf.keras.metrics.AUC()\n",
    "test_auc = tf.keras.metrics.AUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b9624",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinarayCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(total_epoch):\n",
    "    \n",
    "    train_loss.reset_state()\n",
    "    valid_loss.reset_state()\n",
    "    \n",
    "    (x_shuffle,y_shuffle) = shuffle(x_train,y_train)\n",
    "    \n",
    "    for batch in train_batches:\n",
    "        \n",
    "        x_batch = x_shuffle[batch]\n",
    "        y_batch = y_shuffle[batch]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            logits = subclassing_model(x_batch,training=True)\n",
    "            loss = loss_fn(y_batch,logits)\n",
    "        \n",
    "        gradients = tape.gradient(loss,subclassing_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients,subclassing_model.trainable_variables))\n",
    "        train_loss.update_state(loss)\n",
    "        train_acc.update_state(y_batch,logits)\n",
    "        train_auc.update_state(y_batch,logits)\n",
    "        \n",
    "    logits = subclassing_model.predict(x_valid,training=False)\n",
    "    loss = loss_fn(y_valid,logits)\n",
    "    valid_loss.update_state(loss)\n",
    "    valid_acc.update_state(y_valid,logits)\n",
    "    valid_auc.update_state(y_valid,logits)\n",
    "    \n",
    "    print(msg)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9093cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc37b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
